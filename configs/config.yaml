# Model Configuration
model:
  name: "Llama-3.1-70B-Instruct"
  path: "./LLAMA3/prune_llm"

# Pruning Configuration
pruning:
  method: "magnitude"  # Options: magnitude, structured, random
  selected_layers: [0, 1, 2, 7, 3, 4, 6, 8, 9, 12]  

# Optimization Configuration
optimization:
  algorithm: "PSO"  # Any algorithm from Mealpy
  num_generations: 100
  population_size: 50

# Evaluation Configuration
evaluation:
  model_name: "hf"
  tasks: "hellaswag"
  device: "cuda:0"
  batch_size: 8
